{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208fa699-c6e8-4d9b-a395-1772095fb149",
   "metadata": {},
   "source": [
    "## RAG 실습 (2)\n",
    "\n",
    "- 한글 문서에 대해서도 테스트를 해 봅니다.\n",
    "- 문서를 인덱싱 하는 것 외에 원하는 데이터 (FAQ나 Q&A 등) 를 인덱싱하고 사용해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8795b8-699a-4bd4-adf3-cf59700a22fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = os.path.join(\"sample-data\", \"mortgage_kr_guide.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cf1992-0ea8-478c-bff8-fb10b12b5753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed503f9-a2cb-4c7a-8489-324f96940143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26322cc9-1a51-4d75-891f-6fafee8583b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pages)\n",
    "# print(pages[20].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b891af0b-9617-4242-b259-99a9684dbbdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b97d89-55cf-4d9a-b001-bc318e0b557c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd8a782-320c-4ab2-b822-ab2e1d497c88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7eaf6a-c280-40d4-a02c-a50c0173d8e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f\"Number of splitted data: {len(documents)}\")\n",
    "# print(f\"Text sample: {documents[10].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58a1ff-e870-4087-a21d-9b280724ce16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(documents[85].metadata[\"source\"])\n",
    "print(documents[85].metadata[\"page\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5a239-fd25-4172-877c-e00c838d34b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "bedrock = boto3.client(\"bedrock-runtime\")\n",
    "embedding_model_id = \"amazon.titan-embed-text-v2:0\"\n",
    "embedding_dimension = 1024\n",
    "\n",
    "def get_embedding_output(query):\n",
    "    \n",
    "    try:\n",
    "        body = {\n",
    "            \"inputText\": query,\n",
    "            \"dimensions\": embedding_dimension,\n",
    "            \"normalize\": True\n",
    "        }\n",
    "\n",
    "        response = bedrock.invoke_model(\n",
    "            body=json.dumps(body), \n",
    "            modelId=embedding_model_id,\n",
    "            accept='application/json',\n",
    "            contentType='application/json')\n",
    "\n",
    "        response_body = json.loads(response.get(\"body\").read())\n",
    "        embedding = response_body.get(\"embedding\")\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac1733-c27f-461d-8bec-0ad943892682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "for doc in documents:\n",
    "    content = doc.page_content\n",
    "    meta = doc.metadata\n",
    "    embedding = get_embedding_output(content)\n",
    "    \n",
    "    if embedding and len(embedding) == embedding_dimension:\n",
    "        data_list.append({\n",
    "            \"content\": content,\n",
    "            \"content_embeddings\": embedding,\n",
    "            \"metadata\": meta,\n",
    "        })\n",
    "        # print(\"Success to get index\")\n",
    "    else:\n",
    "        print(f\"Error: {content}\")\n",
    "        \n",
    "print(\"Finished to get embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1291d23-0d54-4c51-a852-9c8b3a3e3a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Raw doc size: {len(documents)}\")\n",
    "print(f\"Data to index size: {len(data_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd094ad-d6f6-4478-ad5a-434698bf5c84",
   "metadata": {},
   "source": [
    "### 추가적인 데이터 인덱싱\n",
    "\n",
    "- 여기서는 question, answer 형태의 데이터를 추가로 넣어주도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c0e92-f24b-4f96-924c-253c863f4bd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qna_list = [\n",
    "    {\n",
    "        \"question\": \"가나다는 어떤 회사인가요?\",\n",
    "        \"answer\": \"가나다 코퍼레이션은 대전 서구에 위치한 부동산 법률 해석을 전문으로 하는 회사입니다.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"회사 업무시간에 식사 어떻게 하나요\",\n",
    "        \"answer\": \"3층에 위치한 식당을 이용하는 것이 가장 좋습니다.\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"휴가 사용을 어떻게 해야 하나요?\",\n",
    "        \"answer\": \"팀장의 승인을 받은 후 사내 인트라넷의 인사 - 휴가 - 휴가 신청 메뉴에서 신청하시면 됩니다.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6848bab-75fc-4b35-abfc-b888c31f1790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qna_data_list = []\n",
    "for qna in qna_list:\n",
    "    embedding = get_embedding_output(qna[\"question\"])\n",
    "    qna_data_list.append({\n",
    "        \"content\": qna[\"answer\"],\n",
    "        \"content_embeddings\": embedding,\n",
    "        \"metadata\": {\"source\" : \"Q&A\", \"page\": 0,}\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863ea01-b820-46dc-af9c-b99d15482949",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a1b2a-ffaa-4ca3-a95d-3ea7757d6c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61432cf6-a56e-45fe-9153-198b66ef0ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1204c-edbd-44cd-a899-15079509f648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(collection_name)\n",
    "    print(vector_index_name)\n",
    "    print(aoss_endpoint)\n",
    "except:\n",
    "    collection_name = \"rag-hol-aoss-collection\"\n",
    "    vector_index_name = \"rag-hol-index-vector\"\n",
    "    aoss_endpoint = \"1zo3f6fuhn7vowcv1ld7.us-west-2.aoss.amazonaws.com\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17aaf5-7a6f-4281-b960-6895e4b076c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "import boto3\n",
    "import botocore\n",
    "import time\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,\n",
    "                   region, service, session_token=credentials.token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb38fc6-5764-486e-966d-a8037e91fb4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_aoss_client(host):\n",
    "    client = OpenSearch(\n",
    "        hosts=[{'host': host, 'port': 443}],\n",
    "        http_auth=awsauth,\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        connection_class=RequestsHttpConnection,\n",
    "        timeout=6000\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68b171-3b72-491c-872f-46f931fb06d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aoss_client = get_aoss_client(aoss_endpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50557ff6-5f37-49f1-bcc8-6f5af96e31fb",
   "metadata": {},
   "source": [
    "### 인덱싱 진행\n",
    "\n",
    "- 기존 문서를 파싱한 내용과 QnA 스타일로 추출한 내용을 인덱싱합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bae349-fff8-4e75-95c6-3329f6a9ed5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    try:\n",
    "        response = aoss_client.index(index=vector_index_name, body=data)\n",
    "        # print(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "print(\"Finished to index data to AOSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa1dea-72e5-4701-b7cb-d79aa59f337c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for qna_data in qna_data_list:\n",
    "    try:\n",
    "        response = aoss_client.index(index=vector_index_name, body=qna_data)\n",
    "        # print(response)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "print(\"Finished to index data to AOSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffaa6c6-6f7d-47ce-94ec-2291417fad36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock = boto3.client(\"bedrock-runtime\")\n",
    "bedrock_model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "embedding_model_id = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "def get_llm_output(prompt):\n",
    "    body = json.dumps({\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": 1024,\n",
    "                \"temperature\" : 0.1,\n",
    "                \"top_p\": 0.5,\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                        ],\n",
    "                    }\n",
    "                ],\n",
    "            }) \n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, \n",
    "        modelId=bedrock_model_id,\n",
    "        accept='application/json',\n",
    "        contentType='application/json')\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    llm_output = response_body.get(\"content\")[0].get(\"text\")\n",
    "    return llm_output\n",
    "\n",
    "def get_embedding_output(query):\n",
    "    \n",
    "    body = {\n",
    "        \"inputText\": query,\n",
    "        \"dimensions\": 1024,\n",
    "        \"normalize\": True\n",
    "    }\n",
    "    \n",
    "    response = bedrock.invoke_model(\n",
    "        body=json.dumps(body), \n",
    "        modelId=embedding_model_id,\n",
    "        accept='application/json',\n",
    "        contentType='application/json')\n",
    "\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    embedding = response_body.get(\"embedding\")\n",
    "    return embedding\n",
    "\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You're an expert on real estate and loans.\n",
    "Using the information in the <CONTEXT> as a guide, answer the question. Be as detailed as possible in your answer.\n",
    "In the <CONTEXT>, SOURCE is the source and PAGE is the part of the source.\n",
    "If the <CONTEXT> is missing or you're not sure of the answer, say you don't know. If the user is asking a greeting or a general question, give a general answer.\n",
    "\n",
    "The output should be organized in JSON format, with \"answer\" key containing the answer and \"ref\" key containing a sources. You should put the user's intent in \"intent\" key, which should be \"rag\" if the answer is based on <CONTEXT>, \"general\" if it's a casual question, or \"unknown\" if you don't know the intent.\n",
    "\n",
    "<CONTEXT>\n",
    "{context}\n",
    "</CONTEXT>\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "def get_semantic_rag(user_query):\n",
    "    vector = get_embedding_output(user_query)\n",
    "    vector_query = {\n",
    "      \"query\": {\n",
    "        \"knn\": {\n",
    "          \"content_embeddings\": {\n",
    "            \"vector\": vector,\n",
    "            \"k\": 5\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    response = aoss_client.search(index=vector_index_name, body=vector_query, size=5)\n",
    "    vector_search_results = [result[\"_source\"][\"content\"] for result in response[\"hits\"][\"hits\"]]\n",
    "    \n",
    "    context_data = \"\\n\\n\".join(vector_search_results)\n",
    "    \n",
    "    llm_input = prompt_template.format(context=context_data, question=user_query)\n",
    "    \n",
    "    llm_output = get_llm_output(llm_input)\n",
    "    \n",
    "    return {\"llm_input\": llm_input, \"llm_output\": llm_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259a2c2a-5cec-4bbb-b390-fd37258cf89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904840be-bb5e-44e1-8699-a889599fb135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_normalized_result(search_results, add_meta, weight=1.0):\n",
    "    hits = search_results[\"hits\"][\"hits\"]\n",
    "    if len(hits) == 0:\n",
    "        return []\n",
    "    \n",
    "    max_score = float(search_results[\"hits\"][\"max_score\"])\n",
    "    \n",
    "    results = []\n",
    "    for hit in hits:\n",
    "        normalized_score = float(hit[\"_score\"]) / max_score\n",
    "        weight_score = normalized_score if weight == 1.0 else normalized_score * weight\n",
    "        results.append({\n",
    "            \"doc_id\": hit[\"_id\"],\n",
    "            \"score\": weight_score,\n",
    "            \"content\": hit[\"_source\"][\"content\"],\n",
    "            \"meta\": add_meta,\n",
    "            \"source_doc\" : hit[\"_source\"][\"metadata\"][\"source\"],\n",
    "            \"page\" : hit[\"_source\"][\"metadata\"][\"page\"],\n",
    "        })\n",
    "        \n",
    "    return results\n",
    "\n",
    "def get_hybrid_rag(user_query):\n",
    "    result_limit = 5\n",
    "    vec_weight = 0.6\n",
    "    lex_weight = 0.55\n",
    "    threshold = 0.05\n",
    "    \n",
    "    # Get vector search result\n",
    "    vector = get_embedding_output(user_query)\n",
    "    vector_query = {\n",
    "      \"query\": {\n",
    "        \"knn\": {\n",
    "          \"content_embeddings\": {\n",
    "            \"vector\": vector,\n",
    "            \"k\": 5\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    vector_response = aoss_client.search(index=vector_index_name, body=vector_query, size=10)\n",
    "    vector_result = get_normalized_result(vector_response, \"vector\", vec_weight)\n",
    "    \n",
    "    # Get lexical search result\n",
    "    keyword_query = {\"query\": {\"match\": {\"content\": query_text}}}\n",
    "    keyword_response = aoss_client.search(index=vector_index_name, body=keyword_query, size=10)\n",
    "    keyword_result = get_normalized_result(keyword_response, \"lexical\", lex_weight)\n",
    "    \n",
    "    vector_ids = [vec[\"doc_id\"] for vec in vector_result]\n",
    "    for keyword in keyword_result:\n",
    "        if keyword[\"doc_id\"] not in vector_ids:\n",
    "            vector_result.append(keyword)\n",
    "    \n",
    "    items = vector_result\n",
    "    sorted_items = list(filter(lambda val: val[\"score\"] > threshold, items))\n",
    "    \n",
    "    if len(sorted_items) > result_limit:\n",
    "        sorted_items = sorted_items[:result_limit]\n",
    "    \n",
    "    context_list = []\n",
    "    for item in sorted_items:\n",
    "        context = item[\"content\"] + \"\\nSOURCE: \" + item[\"source_doc\"] + \"\\nPAGE :\" + str(item[\"page\"])\n",
    "        context_list.append(context)\n",
    "    \n",
    "    context_data = \"\\n\\n\".join(context_list)\n",
    "    \n",
    "    # context_data = \"\\n\\n\".join([item[\"content\"] for item in sorted_items])\n",
    "    llm_input = prompt_template.format(context=context_data, question=user_query)\n",
    "    llm_output = get_llm_output(llm_input)\n",
    "    return {\"llm_input\": llm_input, \"llm_output\": llm_output, \"search_result\": sorted_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347b15c-85f5-40a9-8486-ac3faae571b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70282d9b-cd73-4726-aa05-f57d2748cff5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_text = \"전세안심대출 할 때 주의해야 될 사항에 대해서 알려주세요.\"\n",
    "output = get_hybrid_rag(query_text)\n",
    "print(output[\"llm_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edb3b2c-1af8-4a6e-9977-19ea09f2378f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71335e-1f5d-4d91-9f2c-6d43c5397d35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_text = \"반갑습니다.\"\n",
    "output = get_hybrid_rag(query_text)\n",
    "print(output[\"llm_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91523aa-af22-4174-bd07-f4b9eb1e5c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830cc833-328f-456e-95d9-70e109afa54c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_text = \"가나다는 뭐하는 회사에요? 그리고 휴가 신청 어떻게 하죠?\"\n",
    "output = get_hybrid_rag(query_text)\n",
    "print(output[\"llm_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08af80-3bef-4703-991f-b82f602281f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6e4330-6756-4899-adb5-efe82c0c30cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8efd65-1249-44e5-bbb3-9bf23301a75a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bca0ab-486f-4b04-9f0e-f4a27a2fb05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411fe3d-d14a-4849-8671-2bc83c4a6772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
