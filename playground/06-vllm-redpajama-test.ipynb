{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed67c49-2838-4d45-a5ba-f71f12e8a680",
   "metadata": {},
   "source": [
    "## vLLM test\n",
    "\n",
    "vLLM uses PagedTransformer and it boost the inference speed of LLM. It can be helpful for the production service.\n",
    "- vLLM github : https://github.com/vllm-project/vllm\n",
    "- vLLM blog : https://vllm.ai/\n",
    "\n",
    "vLLM is still actively developing, here is the roadmap: https://github.com/vllm-project/vllm/issues/244\n",
    "- Note that currently int8 quantization and Falcon model is not supported yet.\n",
    "- Therefore, 7B model needs more than 21GB GPU RAM, which means g5 is needed for deploying 7B model\n",
    "- Here we tessted `vllm 0.1.1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba821d1-5e62-4de3-9730-1a15bc178e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c4cc66-bf68-4d09-8f54-92302ba5f673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list | grep vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d2562-5039-40de-bac0-c2d3a8bb1060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"pretrained-models/models--togethercomputer--RedPajama-INCITE-7B-Chat/snapshots/47b94a739e2f3164b438501c8684acc5d5acc146\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e165ace-9e09-4954-9e0e-9e63682e72dd",
   "metadata": {},
   "source": [
    "### Setting generation parameters\n",
    "\n",
    "vLLM uses own wrapper so need to change parameter name. Check the official code.\n",
    "- SamplingParams code : https://github.com/vllm-project/vllm/blob/main/vllm/sampling_params.py\n",
    "\n",
    "For example, `max_new_tokens` is `max_tokens` in vLLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2564890-c623-40e3-841a-e26095511305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "llm = LLM(model=model_path)  # Create an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0555c2-9475-4e79-83f2-2f0719830451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = [\"<human>:\", \"<bot>:\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4a55e-e8be-4e17-b596-e548920bdc40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(\n",
    "    temperature=0.8,\n",
    "    top_p=0.8,\n",
    "    # max_tokens=128,\n",
    "    max_tokens=512,\n",
    "    stop=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce251b-b9b6-46a0-8ab6-43359b8d998f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"Do you know why the economic crisis happened in turkey?\"\n",
    "prompt = f\"<human>: {query}\\n<bot>:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480391c9-4af4-4ae1-b320-c4bf6ccfe7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "output = llm.generate([prompt], sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f695487-de86-49c3-a143-f3e6cf19c639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_text = output[0].outputs[0].text\n",
    "print(f\"Output: {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40afb3-2f5f-4a3e-a4f3-b6e1ce750e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2fd03-91a4-451c-b18b-a42039107e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"do you explain what is training and inference in machine learning?\"\n",
    "prompt = f\"<human>: {query}\\n<bot>:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46ce76-0925-4b1f-ada8-0f1ff51e261b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "output = llm.generate([prompt], sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfb3b0-8eb4-4c02-aa9c-cacf80a7f376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generated_text = output[0].outputs[0].text\n",
    "print(f\"Output: {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2841f17-0d7b-43cf-b480-393fca788fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee295630-00dc-4573-a0d0-fa70044fa2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d881591-ee8d-414b-9fbc-cfc987fd0606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# import json\n",
    "# import sagemaker\n",
    "# from sagemaker.utils import name_from_base\n",
    "# from sagemaker import image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045f97e-fbff-4682-ab0c-5048b556e4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sagemaker_session = sagemaker.Session()\n",
    "# role = sagemaker.get_execution_role()\n",
    "# sm_client = sagemaker_session.sagemaker_client\n",
    "# sm_runtime_client = sagemaker_session.sagemaker_runtime_client\n",
    "# s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ee2a1-b22e-4601-97f0-0cb1f74053f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5a013-0b7f-4aa2-8a95-6c7de27d4460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898106c-a272-4a32-8a03-e92252d4d39f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f61ef-31ae-44bc-91af-60eef7623be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1445041-a0d6-4211-876d-1cac58a64e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1117f04e-b5ae-4362-8b44-758d3931cad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0c482-300c-460f-9ea1-a9af26a2dfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
