{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ced60d9-d73b-450b-a10d-9cd7f12f6a4a",
   "metadata": {},
   "source": [
    "## Test MPT model\n",
    "\n",
    "- MPT official blog : https://www.mosaicml.com/blog/mpt-7b\n",
    "- Instruct MPT : https://huggingface.co/mosaicml/mpt-7b-instruct\n",
    "- Chat MPT (Non-commercial) : https://huggingface.co/mosaicml/mpt-7b-chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bf7e1e-932f-49e3-a700-604d2f7daf66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate sentencepiece bitsandbytes einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74339017-c784-48a5-8278-ac4d98f142ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import transformers\n",
    "import torch\n",
    "print(sagemaker.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79730553-2c8d-4f19-89f8-a3a81093c14c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "local_model_path = Path(\"./pretrained-models\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "instruct_model_name = \"mosaicml/mpt-7b-instruct\"\n",
    "chat_model_name = \"mosaicml/mpt-7b-chat\"\n",
    "\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.txt\", \"*.model\", \"*.py\"]\n",
    "\n",
    "instruct_model_path = snapshot_download(\n",
    "    repo_id=instruct_model_name,\n",
    "    cache_dir=local_model_path,\n",
    "    allow_patterns=allow_patterns,\n",
    ")\n",
    "\n",
    "chat_model_path = snapshot_download(\n",
    "    repo_id=chat_model_name,\n",
    "    cache_dir=local_model_path,\n",
    "    allow_patterns=allow_patterns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a08957-d137-4db0-bff5-378a372db84d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Instruct model path: {instruct_model_path}\")\n",
    "print(f\"Chat model path: {chat_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2609a1f-147c-4149-b5bf-9fe6498c191f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "model_path = instruct_model_path\n",
    "# model_path = chat_model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_path,\n",
    "#     trust_remote_code=True,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "# )\n",
    "\n",
    "# int8 quantization is not works now\n",
    "# instruct model works well, but chat model have CUDA OOM error when torch_dtype=torch.bfloat16 is not specified.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model.to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5ecd8a-58a3-47ed-b097-4dd0971322ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instruct prompt example\n",
    "INSTRUCTION_KEY = \"### Instruction:\"\n",
    "RESPONSE_KEY = \"### Response:\"\n",
    "INTRO_BLURB = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "PROMPT_FOR_GENERATION_FORMAT = \"\"\"{intro}\n",
    "{instruction_key}\n",
    "{instruction}\n",
    "{response_key}\n",
    "\"\"\".format(\n",
    "    intro=INTRO_BLURB,\n",
    "    instruction_key=INSTRUCTION_KEY,\n",
    "    instruction=\"{instruction}\",\n",
    "    response_key=RESPONSE_KEY,\n",
    ")\n",
    "\n",
    "# query = \"I can't find my car key today. I visited home, bus, train stop and company today. How can I find my key? Explain it step by step.\"\n",
    "query = \"I got a cold 10 days ago, but still it has no progress. How can I get better? Explain it step by step.\"\n",
    "prompt = PROMPT_FOR_GENERATION_FORMAT.format(instruction=query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685f975-585b-4261-8f5a-b99001da13ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chat prompt example\n",
    "prompt = \"I can't find my car key today. I visited home, bus, train stop and company today. How can I find my key?\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0afacfa-7641-46bd-991f-11aa355d0797",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f691cdc-6567-4476-a40e-e02a9936d413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tokens = model.generate(\n",
    "  **inputs,\n",
    "  max_new_tokens=256,\n",
    "  temperature=0.5,\n",
    "  do_sample=True\n",
    ")\n",
    "\n",
    "output = tokenizer.decode(tokens[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd2f7f-51ed-4edb-93d5-c9825cf3a562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ebc790-9c04-4d5b-9f97-cd02e2874213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbda08-4019-4a93-a805-92eb8326a19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fd80c-1274-4edb-b342-11ae97e2457f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bb4b22-e181-4168-9c58-feea5d241c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
