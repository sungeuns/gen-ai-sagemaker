{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fec04c4-5046-4ea5-b866-15ad4901dc51",
   "metadata": {},
   "source": [
    "## Testing Redpajama 7B model\n",
    "\n",
    "- Redpajama 7B chat model : https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat\n",
    "- Download models from HF model hub (RedPajama 7B Chat)\n",
    "- Local testing\n",
    "- DJL deploy and testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c0fd2-2a11-41ba-a6c2-2025e8555bea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate sentencepiece bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c215321-3c50-401c-b69e-7a4b59edeae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import transformers\n",
    "print(sagemaker.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f0bfeb-d95e-4e6f-9248-f10e946695ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list | grep scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5aa9f7-5b47-413f-ae23-c36faed9b54a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "local_model_path = Path(\"./pretrained-models\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = \"togethercomputer/RedPajama-INCITE-7B-Chat\"\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.txt\", \"*.model\", \"*.py\"]\n",
    "\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    cache_dir=local_model_path,\n",
    "    allow_patterns=allow_patterns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1def9-681c-4fa0-a817-5d2960ca4479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Local model download path: {model_download_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023abdd-9819-4486-97da-8eb8a2bdce2e",
   "metadata": {},
   "source": [
    "### Local mode testing\n",
    "\n",
    "- Testing model on local mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e20c77-8bd3-43ea-abe6-ef1c4b58e36e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143f29b1-5ee1-4ce7-994a-8f3566d83fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_download_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_download_path,\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b7fee9-2857-4038-a2f0-449901c60835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query = \"could you recommend the places in korea to travel with my baby and wife?\"\n",
    "# query = \"How to convert standard s3 class to glacier with code in Java?\"\n",
    "query = \"Could you show me the code sample to upload large file on s3 in typescript?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ed8f3-7f9f-43a4-b26b-a25f6c49ce12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f\"<human>: {query}\\n<bot>:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a6aa7-ac0f-45f1-81fb-3b2d71f01417",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35b9c3-b902-4704-ab95-16ae0f05442c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stopping condition from: https://discuss.huggingface.co/t/implimentation-of-stopping-criteria-list/20040/7\n",
    "\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "stop_words = [\"<human>:\", \"<bot>:\"]\n",
    "\n",
    "class StoppingCriteriaSub(StoppingCriteria):\n",
    "\n",
    "    def __init__(self, stops = [], encounters=1):\n",
    "        super().__init__()\n",
    "        self.stops = [stop.to(\"cuda\") for stop in stops]\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "        for stop in self.stops:\n",
    "            if torch.all((stop == input_ids[0][-len(stop):])).item():\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "    \n",
    "stop_words_ids = [tokenizer(stop_word, return_tensors='pt')['input_ids'].squeeze() for stop_word in stop_words]\n",
    "print(f\"Stop word ids: {stop_words_ids}\")\n",
    "stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_words_ids)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f3643-47d0-4c57-bd8b-bbb3d57679bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "input_length = inputs.input_ids.shape[1]\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    temperature=0.5,\n",
    "    top_p=0.5,\n",
    "    top_k=50,\n",
    "    return_dict_in_generate=True,\n",
    "    early_stopping=True,\n",
    "    stopping_criteria=stopping_criteria\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cffbbdd-1680-4f0f-b45d-38388218afb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = outputs.sequences[0, input_length:]\n",
    "output_str = tokenizer.decode(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fd0ee-3211-484f-868d-b0924d661390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89499c-a956-43d3-852e-e8db7c85489a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_stopword(output, stop_words):\n",
    "    for stop_word in stop_words:\n",
    "        if output[-len(stop_word):] == stop_word:\n",
    "            return output[:-len(stop_word)]\n",
    "    return output\n",
    "\n",
    "result = remove_stopword(output_str, stop_words)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc5413-a5a3-4ba7-b4c1-184826f33e94",
   "metadata": {},
   "source": [
    "### SageMaker Deployment testing\n",
    "\n",
    "- Deploy model to SageMaker endpoint using DJL\n",
    "\n",
    "\n",
    "### TODO\n",
    "- DeepSpeed wrapping (ing)\n",
    "- int8 quantization g4dn.2xlarge deployment\n",
    "- Async inference\n",
    "\n",
    "\n",
    "### Test\n",
    "- g5.4xlarge int8 : 15~20s\n",
    "- g5.4xlarge fp16 deepspeed : 15~20s (The result is strange)\n",
    "- g4dn.2xlarge int8 : very slow ...!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ab37e8-880e-4441-b6e1-e183f4fca560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_model_prefix = \"llm/redpajama/model\"  # folder where model checkpoint will go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf53c6-298f-46de-b9cc-a5a8f0ff1624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model_s3 = f\"{s3_model_prefix}/chat-7b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497aa1c3-7c48-4deb-b06e-0e0395644c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "s3_model_artifact = sagemaker_session.upload_data(path=model_download_path, key_prefix=base_model_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85490927-9cec-4090-95c6-3cff6ed1cce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Model s3 uri : {s3_model_artifact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96e350-14d6-4373-8970-5beb9585c8f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cec77-1e24-49fc-a4ab-c4be51ec2cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker import image_uris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9baf263-4b10-4afc-b443-169d9ceb9b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sm_client = sagemaker_session.sagemaker_client\n",
    "sm_runtime_client = sagemaker_session.sagemaker_runtime_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80945a0-d302-4a24-8eeb-91139ff1c1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"sagemaker role: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd07d62-6843-4405-bd30-54040cf7a339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm_engine = \"deepspeed\"\n",
    "llm_engine = \"fastertransformer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa437a-b4ce-4db0-8afb-f5baabde049d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "framework_name = f\"djl-{llm_engine}\"\n",
    "inference_image_uri = image_uris.retrieve(\n",
    "    framework=framework_name, region=sagemaker_session.boto_session.region_name, version=\"0.21.0\"\n",
    ")\n",
    "\n",
    "print(f\"Inference container uri: {inference_image_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75258f6e-1f12-44c1-88fd-aa0164a0deb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_dir_name = f\"redpajama-7b-src\"\n",
    "s3_target = f\"s3://{sagemaker_session.default_bucket()}/llm/redpajama/code/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432bd9a-0412-4799-b3c3-13788418ac0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {src_dir_name}.tar.gz\n",
    "!tar zcvf {src_dir_name}.tar.gz {src_dir_name} --exclude \".ipynb_checkpoints\" --exclude \"__pycache__\"\n",
    "!aws s3 cp {src_dir_name}.tar.gz {s3_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d07c0-5851-4a66-8e5e-4b5355cfcf44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_uri = f\"{s3_target}{src_dir_name}.tar.gz\"\n",
    "print(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e1bd3-7932-43bf-9400-7c2669a66341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = name_from_base(f\"redpajama-7b-djl\")\n",
    "print(model_name)\n",
    "\n",
    "create_model_response = sm_client.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    PrimaryContainer={\"Image\": inference_image_uri, \"ModelDataUrl\": model_uri},\n",
    ")\n",
    "model_arn = create_model_response[\"ModelArn\"]\n",
    "\n",
    "print(f\"Created Model: {model_arn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a6738-421d-4351-b22f-556faa96db41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g4dn.2xlarge\"\n",
    "# instance_type = \"ml.g5.4xlarge\"\n",
    "\n",
    "endpoint_config_name = f\"{model_name}-config\"\n",
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 600,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(endpoint_config_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f7b4b-473d-4231-a5a7-215b97842441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca8153-6dd3-4614-a67e-e4441dc19d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a907842-a84f-4464-b1ee-ebd9aa08831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcf0a9f-6457-4aaa-bc14-a176450963c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Do you know why the italy and spain had a economic crisis before?\"\n",
    "query = \"Can you recommend my newborn baby's name?\"\n",
    "\n",
    "prompt = f\"<human>: {query}\\n<bot>:\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fa0a83-44cf-42ab-87de-72f673624387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "prompts = [prompt]\n",
    "\n",
    "response_model = sm_runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(\n",
    "        {\n",
    "            \"text\": prompts,\n",
    "            \"parameters\": {\n",
    "                # \"max_new_tokens\": 512,\n",
    "                \"max_new_tokens\": 128,\n",
    "                \"temperature\": 0.5,\n",
    "                \"do_sample\": True,\n",
    "                \"top_p\": 0.5,\n",
    "                \"top_k\": 50,\n",
    "                \"early_stopping\": True\n",
    "            },\n",
    "        }\n",
    "    ),\n",
    "    ContentType=\"application/json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0593e0-fba4-4a9b-9f5b-f0b277dcb599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = str(response_model[\"Body\"].read(), \"utf-8\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c1d49-d406-426f-8336-90a52acc58ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2a02a61-747d-4e22-944e-9ecdd92f0ca4",
   "metadata": {},
   "source": [
    "### Deploy to async endpoint\n",
    "\n",
    "- LLM takes long time so real time inference is not a good way to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce8a09-4ba6-47a4-97f6-9c6ef23be70b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "default_bucket = sagemaker_session.default_bucket()\n",
    "async_output_uri = f\"s3://{default_bucket}/llm/outputs/{model_name}/\"\n",
    "print(async_output_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472b5e7-3b33-4e28-8d08-713f9b2e94dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g4dn.xlarge\"\n",
    "# instance_type = \"ml.g5.2xlarge\"\n",
    "\n",
    "endpoint_config_name = f\"{model_name}-async-config\"\n",
    "endpoint_name = f\"{model_name}-async-endpoint\"\n",
    "\n",
    "endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\",\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": 600,\n",
    "        },\n",
    "    ],\n",
    "    AsyncInferenceConfig={\n",
    "        \"OutputConfig\": {\n",
    "            \"S3OutputPath\": async_output_uri,\n",
    "        },\n",
    "        \"ClientConfig\": {\n",
    "            \"MaxConcurrentInvocationsPerInstance\": 1\n",
    "        }\n",
    "    }\n",
    ")\n",
    "print(endpoint_config_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60453322-2932-492a-8697-1b7d98b60379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=f\"{endpoint_name}\", EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(f\"Created Endpoint: {create_endpoint_response['EndpointArn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5bfc7-b090-4af2-9a7a-7222f0535d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14277627-44cb-43b3-a7f8-b899726c8985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import boto3\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91156ed2-5d92-4594-bf64-4c984c6079af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompts = [prompt]\n",
    "input_data = {\n",
    "    \"text\": prompts,\n",
    "    \"parameters\": {\n",
    "        # \"max_new_tokens\": 512,\n",
    "        \"max_new_tokens\": 128,\n",
    "        \"temperature\": 0.5,\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.5,\n",
    "        \"top_k\": 50,\n",
    "        \"early_stopping\": True\n",
    "    },\n",
    "}\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5057cfc8-db37-4427-97db-82e10dd1743e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload input data onto the S3\n",
    "s3_uri = f\"llm/inputs/{model_name}/{uuid.uuid4()}.json\"\n",
    "s3_client.put_object(\n",
    "    Bucket=default_bucket,\n",
    "    Key=s3_uri,\n",
    "    Body=json.dumps(input_data))\n",
    "\n",
    "input_data_uri = f\"s3://{default_bucket}/{s3_uri}\"\n",
    "input_location = input_data_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7176144-1dad-4a2a-8d08-296192787259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sm_runtime_client.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name, \n",
    "    InputLocation=input_location\n",
    ")\n",
    "output_location = response[\"OutputLocation\"]\n",
    "print(output_location)\n",
    "output_key_uri = \"/\".join(output_location.split(\"/\")[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dcf83c-ab0a-4864-b85a-1e7807fdc21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    exists = s3_client.head_object(Bucket=default_bucket, Key=output_key_uri)['ResponseMetadata']['HTTPStatusCode'] == 200\n",
    "    if exists:\n",
    "        text_obj = s3_client.get_object(Bucket=default_bucket, Key=output_key_uri)['Body'].read()\n",
    "        text = text_obj.decode('utf-8')\n",
    "        print(text)\n",
    "except:\n",
    "    print(\"Data is not exist yet. Wait until inference finished or check the CW log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d310c-00d9-45f2-b1c4-27e8eb16831f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
