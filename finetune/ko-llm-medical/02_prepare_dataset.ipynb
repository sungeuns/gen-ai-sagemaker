{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa77f3-2697-4482-8b58-906daa4101ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08dfc3cc-a376-4d5b-af98-380211ef717f",
   "metadata": {},
   "source": [
    "## 데이터 준비\n",
    "\n",
    "- 샘플 데이터를 받아서 fine-tuning 가능한 형태로 구성합니다.\n",
    "\n",
    "\n",
    "\n",
    "### 샘플 데이터셋 활용\n",
    "\n",
    "- 링크 : https://huggingface.co/datasets/sean0042/KorMedMCQA\n",
    "- train, dev, test 로 이뤄져 있음.\n",
    "\n",
    "\n",
    "### Format 예시\n",
    "\n",
    "- Solar 예시: https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0\n",
    "- IFT 시 사용 format\n",
    "```\n",
    "<s> ### User:\n",
    "Hello?\n",
    "\n",
    "### Assistant:\n",
    "Hello, how can I assist you today? Please feel free to ask any questions or request help with a specific task.</s>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d711b-aa53-4ad5-be74-08084cbce7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d228b8-00ca-4a91-a7de-830d4a1002ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "data_path = \"sean0042/KorMedMCQA\"\n",
    "\n",
    "doctor = load_dataset(path=data_path, name=\"doctor\")\n",
    "nurse = load_dataset(path=data_path,name=\"nurse\")\n",
    "pharmacist = load_dataset(path=data_path, name=\"pharm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc3b20-ff0c-4e29-acb9-add4afc80172",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7a7576-6bb2-4b51-95af-45e90c711751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_data(data_type):\n",
    "    doctor_set = pd.DataFrame(doctor[data_type])\n",
    "    nurse_set = pd.DataFrame(nurse[data_type])\n",
    "    pharmacist_set = pd.DataFrame(pharmacist[data_type])\n",
    "    \n",
    "    return pd.concat([doctor_set, nurse_set, pharmacist_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9afaa-ce26-4887-af9d-292f8803c06c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = merge_data('train')\n",
    "val_df = merge_data('dev')\n",
    "test_df = merge_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797f464-65ea-46e3-8109-d4ba7db69435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5595343-bdfc-4a4f-b930-ce6a8b0ebed5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 데이터 준비\n",
    "\n",
    "- 데이터를 적절하게 전처리하여 원하는 형태로 만들어 놓도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2c099-85cf-487c-a572-1a9cbdd5c0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def refine_text(df):\n",
    "    answer_list = []\n",
    "    for row in df.itertuples():\n",
    "        question = row[5]\n",
    "        answer_idx = int(row[11])\n",
    "        answer = row[5 + answer_idx]\n",
    "        answer_list.append(answer)\n",
    "    \n",
    "    input_df = df[\"question\"].to_frame()\n",
    "    final_df = input_df.assign(output=answer_list)\n",
    "    # final_df = df.assign(output=answer_list)\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def refine_text_v2(df):\n",
    "    answer_list = []\n",
    "    for row in df.itertuples():\n",
    "        question = row[5]\n",
    "        answer_idx = int(row[11])\n",
    "        # answer = row[5 + answer_idx]\n",
    "        \n",
    "        answer = f\"질문에 대한 후보는 {row[6]}, {row[7]}, {row[8]}, {row[9]}, {row[10]} 가 될 수 있는데, 가장 올바른 정답은 {row[5 + answer_idx]} 입니다.\"\n",
    "        answer_list.append(answer)\n",
    "    \n",
    "    input_df = df[\"question\"].to_frame()\n",
    "    final_df = input_df.assign(output=answer_list)\n",
    "    # final_df = df.assign(output=answer_list)\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc997a4-5c61-4c14-82c9-201bc0ab48cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = refine_text_v2(train_df)\n",
    "val_set = refine_text_v2(val_df)\n",
    "# test_set = refine_text_v2(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f14305-7ff9-4220-9614-0935398ceef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9b5da-2533-4b87-a4b9-fdf4a8c312e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set['question_length'] = train_set['question'].apply(len)\n",
    "train_set['output_length'] = train_set['output'].apply(len)\n",
    "print(train_set.describe())\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf6f83-0d94-4032-a497-84d2364bb363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cutoff_len = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce961b7-a27f-4c14-8e16-2e699333688c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Sample question: {train_set.iloc[0].question}\")\n",
    "print(f\"Sample answer: {train_set.iloc[0].output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c17e966-9dcc-456d-9b5f-23171174dfb0",
   "metadata": {},
   "source": [
    "### Tokenized 된 데이터 준비\n",
    "\n",
    "- 실제 학습은 일반적인 text가 아니라 token 값을 활용하게 되므로, text를 token으로 변환해 놓도록 합니다.\n",
    "- 학습을 위한 프롬프트 형태로 만들어서 instruction tuning을 합니다. 위의 포맷을 참고해 주세요. 해당 포맷을 반드시 사용할 필요는 없지만, fine-tuning을 하기 위한 모델의 포맷을 따라가는 것이 좋습니다.\n",
    "- 여기서 실제 학습에 활용되는 값은 `input_ids` 이며, 추가적으로 `labels`나 `attention_mask`가 활용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad47809-632f-4476-97fc-2f9f732607e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a3969-5c6e-4d33-8fa2-1bbf400987d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_download_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b27de6-03d4-4209-8032-9422d8679b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d7ee5-5815-4c05-860e-54d3f3c195cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3c398b-450f-4d31-b61a-e96be6bf83d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(prompt, add_eos_token=True):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=cutoff_len,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < cutoff_len\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    "\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e6dc9c-0ecd-4d36-a2d3-105af64e46d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset):\n",
    "    dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    labels = []\n",
    "    inputs = []\n",
    "    masks = []\n",
    "    for row in dataset.itertuples():\n",
    "        question = row[1]\n",
    "        answer = row[2]\n",
    "#         prompt = f\"\"\"<s> ### User:\n",
    "# {question}\n",
    "\n",
    "# ### Assistant:\n",
    "# {answer} </s>\n",
    "# \"\"\"\n",
    "        \n",
    "        prompt = f\"\"\"### User:\n",
    "{question}\n",
    "\n",
    "### Assistant:\n",
    "{answer}\n",
    "\"\"\"\n",
    "        \n",
    "        tokenized_result = tokenize(prompt)\n",
    "        inputs.append(tokenized_result['input_ids'])\n",
    "        labels.append(tokenized_result['labels'])\n",
    "        masks.append(tokenized_result['attention_mask'])\n",
    "    \n",
    "    dataset = dataset.assign(input_ids=inputs)\n",
    "    dataset = dataset.assign(labels=labels)\n",
    "    dataset = dataset.assign(attention_mask=masks)\n",
    "    \n",
    "    return dataset\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef46418-daff-42f3-a378-f84a1c33154d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = prepare_dataset(train_set)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a70d8a4-f505-47b9-81f5-d9e26927947f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset = prepare_dataset(val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4325d8-d472-4c3c-b7b9-cad455605029",
   "metadata": {},
   "source": [
    "### 데이터 저장\n",
    "\n",
    "- 데이터를 로컬에 저장해서 로컬 테스트 용도로 활용합니다.\n",
    "- 필요하다면 s3에 저장해 놓을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd41f78e-48b6-40ac-8242-59525784032b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "hf_train = Dataset.from_pandas(train_dataset)\n",
    "hf_val = Dataset.from_pandas(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c2aa5-d786-4c96-a565-fb75be3c2801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "hf_train.save_to_disk(os.path.join(\"dataset\", \"train\"))\n",
    "hf_val.save_to_disk(os.path.join(\"dataset\", \"val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e3826-4a37-49ee-8c1b-789f1878a6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490e083c-216c-4ebc-96f8-1e9a131dab2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bff45d-743e-4556-a17e-b9c7beae7076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4495d1d-083c-4ff5-b7d6-c34ae446868e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6182d5-4b90-4308-be65-6934204b47be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1636b1b-0912-4f67-9820-f6f18171b914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
