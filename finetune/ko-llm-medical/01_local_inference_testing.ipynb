{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ab37d8-7039-4210-9841-b560d5f93b7e",
   "metadata": {},
   "source": [
    "## 한국어 LLM 로컬 환경 테스트\n",
    "\n",
    "- 먼저 base model 을 하나 선택해서 local mode로 테스트를 진행 해 봅니다.\n",
    "- 모델 예시 : https://huggingface.co/LDCC/LDCC-SOLAR-10.7B\n",
    "\n",
    "### 추천 설치 유틸리티\n",
    "\n",
    "```\n",
    "# Install tools\n",
    "yum -y install ncurses-devel tmux htop libdrm-devel\n",
    "\n",
    "# Install nvtop\n",
    "git clone https://github.com/Syllo/nvtop.git\n",
    "mkdir -p nvtop/build && cd nvtop/build\n",
    "cmake .. -DNVIDIA_SUPPORT=ON -DAMDGPU_SUPPORT=OFF\n",
    "make\n",
    "make install\n",
    "```\n",
    "\n",
    "\n",
    "### Tested version\n",
    "\n",
    "```\n",
    "bitsandbytes              0.43.0\n",
    "datasets                  2.18.0\n",
    "peft                      0.9.0\n",
    "transformers              4.38.2\n",
    "```\n",
    "\n",
    "먼저 필요한 패키지들을 설치합니다.\n",
    "- 아래 명령어는 최신 버전 패키지를 설치하기 때문에, 상황에 따라 위에 명시된 버전으로 설치하는 것을 추천합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc840a-dc01-4579-b815-f154757ac47e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers peft bitsandbytes datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0b126-0ca8-4933-ab95-d4e304c0e0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list | grep 'peft\\|transformers\\|bitsandbytes\\|datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cac0c-84f3-43c8-be77-018c10558281",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 모델 로딩 및 테스트\n",
    "\n",
    "- LLM 활용 시 가장 많이 사용되는 [HF transformers](https://huggingface.co/docs/transformers/index) 를 사용합니다.\n",
    "- [bitsandbytes](https://github.com/TimDettmers/bitsandbytes) 를 사용해서 Quantization을 합니다.\n",
    "- 여기서는 4bit Quantization을 하여 메모리 사용량을 줄입니다.\n",
    "- 모델을 로컬에 다운로드 받고 이것을 로드하여 테스트합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fcd502-1aa4-4f4e-894a-ac2d171d0496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb386f49-751a-48ac-ae77-981ca875a02c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "quant_4bit = True\n",
    "quant_8bit = False\n",
    "\n",
    "if quant_4bit:\n",
    "    nf4_config = BitsAndBytesConfig(\n",
    "       load_in_4bit=True,\n",
    "       bnb_4bit_quant_type=\"nf4\",\n",
    "       bnb_4bit_use_double_quant=True,\n",
    "       bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "else:\n",
    "    nf4_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2f3150-218d-448d-9ba4-b102dca2d979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "HF_MODEL_ID = \"LDCC/LDCC-SOLAR-10.7B\"\n",
    "revision = \"v1.2\"\n",
    "\n",
    "# create model dir\n",
    "model_name = HF_MODEL_ID.split(\"/\")[-1].replace('.', '-')\n",
    "model_tar_dir = Path(f\"/home/ec2-user/SageMaker/models/{model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f34499-43d3-463e-ae6e-1e0bb0e1ceb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.txt\", \"*.model\", \"*.py\", \"*.safetensors\"]\n",
    "\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=HF_MODEL_ID,\n",
    "    cache_dir=model_tar_dir,\n",
    "    allow_patterns=allow_patterns,\n",
    "    revision=revision\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c21cb-5e96-4d83-a10a-862885596466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model_download_path)\n",
    "print(model_tar_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a670973-9069-4851-b0bb-e29b6ac763dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5cdfc-7d47-4720-bdd1-a0d97a04a279",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example: When using specific path\n",
    "# base_model_path = \"base_model/models--LDCC--LDCC-SOLAR-10.7B/snapshots/1055563879363d9ee2fba1d9fd1628eca6bcbb4e\"\n",
    "# model_download_path = \"merged_model\"\n",
    "# model_download_path = \"model_from_sagemaker\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e5240-0600-4cb2-8d94-fcd2e8f5edb4",
   "metadata": {},
   "source": [
    "### Inference 테스트\n",
    "\n",
    "- 모델을 로드하여 테스트합니다.\n",
    "- base model 이 instruction tuning이 된 경우 어떤 포맷을 활용해서 학습이 되어있는지를 확인할 필요가 있습니다.\n",
    "- 예를 들어 solar instruction 같은 경우 [여기](https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0#conducting-single-turn-conversation) 내용과 같은 포맷을 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447dd410-b20a-4b6c-9003-8dffe7d16c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f230ec-3aca-4742-a932-f47b8a81c424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "device_map = \"auto\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_download_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_download_path,\n",
    "    load_in_8bit=True if quant_8bit else False,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    "    quantization_config=nf4_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d9dac-ee91-494d-a2f2-a2543ec8498d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompt = \"초록색 가래가 계속 나오고 기침이 나오는데, 큰 병은 아닐까요?\"\n",
    "# prompt = \"항문압 측정 검사에서 항문 압력이 증가하는 경우는 어떤 경우일까요?\"\n",
    "# prompt = \"55세 남자가 위암으로 위절제술을 받았다. 수술 후 3일째 혈색소가 6.7 g/dL,로 감소하여 농축적혈구 수혈을 시작하였다. 수혈 도중 갑자기 오한과 발열이 발생하였으며, 복부 피부절개 부위에서 혈성 삼출물이 보이고 수혈 주사부위에 통증이 생겼다. 혈압 100/60 mmHg, 맥박 102회/분, 호흡 24회/분, 체온 38.2도 이다. 처치는?\"\n",
    "# prompt = \"감염병 유행 역학조사를 수행하면서 인구학적 특성별, 발생 시기별로 환자발생 점지도(spot map) 를 작성하였다. 이를 통해 알 수 있는 것은?\"\n",
    "# prompt = \"42세 남자가 1개월 전부터 숨이 많이 찬다며 병원에 왔다. 4년 전부터 숨이 찼다고 한다. 1주 전부터는 기침도 하고, 밤에 잘 때 쌕쌕거리는 소리도 난다고 한다. 20갑 ∙ 년의 흡연자이다. 혈압 120/70 mmHg, 맥박 88회/분, 호흡 20회/분, 체온 36.4℃이다. 가슴 청진에서 호흡음은 정상이다. 가슴 X선사진은 정상이다. 폐기능검사 결과는 다음과 같다. 다음 검사는?강제폐활량: 3.0 L (예측치의 92%) 1초간 강제날숨량: 2.7 L (예측치의 90%)\"\n",
    "prompt = \"1개월 남아가 12시간 전부터 피부색이 창백하고 얼룩덜룩하게 변하여 병원에 왔다. 하루 전부터 많이 보채면서 한 번에 분유를 30 mL도 못 먹었지만 배가 불러보였다고 한다. 어딘지 평소와 다르게 보였고, 집에서 측정한 체온은 35.9℃부터 37.7℃까지 오르내렸다. 임신나이 39주, 출생체중 3,300 g, 질분만으로 태어나서, 아프기 전에는 잘 지내왔었다. 혈압 65/45 mmHg, 맥박 155회/분, 호흡 60회/분, 체온 39.2℃이다. 피부색은 창백하고, 진찰하는 동안에도 많이 처져서 잘 울지 않는다. 검사는?\" \n",
    "# prompt = \"우리나라는 환자의 수도권 집중 방지와 지방의 진료 역량 강화를 위하여 수도권을 제외한 시도에 권역 단위로 전문질환센터를 지정하여 지원하고 있다. 권역 전문질환센터의 설립 취지를 반영하는 병원 관리 평가지표는?\"\n",
    "# prompt = \"65세 이상 노인에게서 인플루엔자 예방접종이 폐렴으로 인한 입원율을 낮추는 효과가 있는지 확인하려고 한다. 일정기간 폐렴으로 인한 입원 환자 수는 접종군 4,000명 중 20명, 비접종군 2,000명 중 40명이다. 인플루엔자 예방접종의 폐렴 입원에 대한 예방효과는?\"\n",
    "# prompt = \"펜션에서 투숙객 3명이 혼수상태로 발견되었다. 특별한 외상은 관찰되지 않았으며, 혈액검사에서 일산화탄소헤모글로빈(COHb) 은 40% 이상이었다. 치료는?\"\n",
    "# prompt = \"미생물연구실에서 실험을 하던 25세 여자가 눈의 충혈, 이물감, 시림, 통증으로 병원에 왔다. 이 여자는 보안경을 착용하지 않은 채 무균실험대 위에서 살균등을 켜고 실험을 하였다. 노출이 의심되는 방사선은?\"\n",
    "# prompt = \"42세 남자가 화를 못 참겠다며 병원에 왔다. 1개월 전에 골육종으로 오른쪽 다리를 절단해야 한다는 진단을 받았다. 상급종합병원에서 다시 한 번 검사를 받았으나 결과는 같았다. 왜 이런 일이 생긴 건지 믿을 수가 없다며 화를 내다가도 아직 7개월밖에 안 된 아들을 생각하면 갑자기 눈물이 나와 멈출 수가 없었다. 직장에서는 사소한 일에도 화가 치밀어 동료들과 다툼이 잦아졌고 업무에도 실수가 많아져 사람이 갑자기 변했다는 소리를 들었다고 한다. 밤에는 미래에 대한 걱정으로 잠을 거의 자지 못했고 식욕이 없어 하루에 한 끼를 겨우 먹었다. 치료는?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e6cc99-3d3e-4981-a39d-753a5af4ebcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "당신은 똑똑한 의사입니다. 질문에 대해서 최대한 자세하게 어떤 병인지, 치료법은 무엇인지 환자에게 설명하듯 친절하게 설명해 주세요.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38e789-fcc0-4cdb-9d7c-7f13a88d529f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normal format\n",
    "text = f\"\"\"\n",
    "{instruction}\n",
    "\n",
    "{prompt}\n",
    "\"\"\"\n",
    "\n",
    "# # IFT format\n",
    "# text = f\"\"\"\n",
    "# <s> ### User:\n",
    "# {instruction}\n",
    "\n",
    "# {prompt}\n",
    "\n",
    "# ### Assistant:\n",
    "# \"\"\"\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d253b-f2f9-4ca6-a561-1e84292c1d16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.1,\n",
    "    \"do_sample\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed27a44f-b07c-4812-b99d-a23a120b9b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    model_inputs.input_ids,\n",
    "    **params\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f8401-d6fa-4c86-af6c-5db551230dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3864493-6815-4eeb-8917-3236e6832e97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab4bb5b-c89b-4337-88b7-590708821c32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store model_download_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81a210-f67f-49b3-9900-f8f2b6fb7181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d7bde4-448b-499c-896e-14a94295860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4abba4-a5d7-4283-aabd-e0ee3365244f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67963fd1-eedd-4c9e-a886-abb43d1e5960",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ff824-f172-4e87-a45e-865b16204d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4e454d-b586-47e0-8abb-5beeab118af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
