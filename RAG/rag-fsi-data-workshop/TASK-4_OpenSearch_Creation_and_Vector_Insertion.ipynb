{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed68d00-7a6e-4e82-b5e8-2e7cf442d1d4",
   "metadata": {},
   "source": [
    "## OpenSearch - Vector Store\n",
    "OpenSearch는 대규모 데이터셋에 대한 유사도 검색을 위한 강력한 엔진입니다. Amazon OpenSearch Service를 통해 쉽게 클라우드 환경에서도 이용할 수 있습니다. 이와 함께 Vector Store를 사용하면 고차원 벡터 데이터를 효율적으로 저장하고 빠르게 검색할 수 있어, 복잡한 자연어 처리 작업을 더욱 간편하게 수행할 수 있습니다.\n",
    "\n",
    "* Container: `Data Science 3.0` (studio, python 3.10), `conda_python3` (notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28b250f-7129-41e9-82ae-0385686aacb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Install packages and Setup env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c1e24-ea50-4947-8337-c03d338f0823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('../utils') # src 폴더 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33c231-28ca-4834-b82a-a2a2d423323b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183a551-a694-46e3-a304-f1bf58808390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -qU pip\n",
    "    !{sys.executable} -m pip install -qU sagemaker\n",
    "    !{sys.executable} -m pip install -qU langchain\n",
    "    !{sys.executable} -m pip install -qU faiss-cpu\n",
    "    !{sys.executable} -m pip install -qU opensearch-py\n",
    "    \n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629008bb-4b95-4346-9c6c-27c9af0cd386",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. SageMaker Endpoint Wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e467e-4814-45c0-9d09-a16aea0428da",
   "metadata": {},
   "source": [
    "### 1.1. SageMaker LLM Endpoint Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf2801-9bdb-4129-8f43-1db55695d1cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 앞선 노트북에서 저장한 변수들을 로드합니다.\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7d086-ed27-4d55-97e5-0ddce2863ad2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(endpoint_name)\n",
    "print(embedding_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00402a44-1260-42c6-ad88-f8497db607de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('../utils') # src 폴더 경로 설정\n",
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "from inference_utils import Prompter\n",
    "from typing import Any, Dict, List, Optional\n",
    "from langchain.embeddings import SagemakerEndpointEmbeddings\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler, SagemakerEndpoint\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b2221-5907-4a71-834f-71d40722d3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompter = Prompter(\"kullm\")\n",
    "params = {\n",
    "      'do_sample': False,\n",
    "      'max_new_tokens': 128,\n",
    "      'temperature': 1.0,\n",
    "      'top_k': 0,\n",
    "      'top_p': 0.9,\n",
    "      'return_full_text': False,\n",
    "      'repetition_penalty': 1.1,\n",
    "      'presence_penalty': None,\n",
    "      'eos_token_id': 2\n",
    "}\n",
    "\n",
    "class KullmContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        '''\n",
    "        입력 데이터 전처리 후에 리턴\n",
    "        '''\n",
    "        context, question = prompt.split(\"||SPEPERATOR||\") \n",
    "        prompt = prompter.generate_prompt(question, context)\n",
    "\n",
    "        print (\"prompt\", prompt)\n",
    "        payload = {\n",
    "            'inputs': [prompt],\n",
    "            'parameters': model_kwargs\n",
    "        }\n",
    "                           \n",
    "        input_str = json.dumps(payload)\n",
    "        \n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        \n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))              \n",
    "        generated_text = response_json[0][0][\"generated_text\"]\n",
    "        \n",
    "        return generated_text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a1c17c-a257-42a8-8b65-37e3b1046a0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aws_region = boto3.Session().region_name\n",
    "LLMTextContentHandler = KullmContentHandler()\n",
    "\n",
    "# endpoint_name_text = \"kullm-polyglot-5-8b-v2-2023-08-23-15-47-39-450-endpoint\"\n",
    "endpoint_name_text = endpoint_name\n",
    "\n",
    "seperator = \"||SPEPERATOR||\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216198c-59e9-4903-9bcd-92a73abe7656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_text = SagemakerEndpoint(\n",
    "    endpoint_name=endpoint_name_text,\n",
    "    region_name=aws_region,\n",
    "    model_kwargs=params,    \n",
    "    content_handler=LLMTextContentHandler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc06c71f-1e29-4d08-89da-2d442261cb56",
   "metadata": {},
   "source": [
    "### 1.2. SageMaker Embedding Model Endpoint Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f875b-33b9-41b7-b6c0-b4da7de9745a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SagemakerEndpointEmbeddingsJumpStart(SagemakerEndpointEmbeddings):\n",
    "    def embed_documents(self, texts: List[str], chunk_size: int=1) -> List[List[float]]:\n",
    "        \"\"\"Compute doc embeddings using a SageMaker Inference Endpoint.\n",
    "\n",
    "        Args:\n",
    "            texts: The list of texts to embed.\n",
    "            chunk_size: The chunk size defines how many input texts will\n",
    "                be grouped together as request. If None, will use the\n",
    "                chunk size specified by the class.\n",
    "\n",
    "        Returns:\n",
    "            List of embeddings, one for each text.\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        _chunk_size = len(texts) if chunk_size > len(texts) else chunk_size\n",
    "        \n",
    "        print(\"text size: \", len(texts))\n",
    "        print(\"_chunk_size: \", _chunk_size)\n",
    "\n",
    "        for i in range(0, len(texts), _chunk_size):\n",
    "            \n",
    "            #print (i, texts[i : i + _chunk_size])\n",
    "            response = self._embedding_func(texts[i : i + _chunk_size])\n",
    "            #print (i, response, len(response[0].shape))\n",
    "            \n",
    "            results.extend(response)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f2819-ac24-4cff-9dd1-feae526a794c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KoSimCSERobertaContentHandler(EmbeddingsContentHandler):\n",
    "    \n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs={}) -> bytes:\n",
    "        \n",
    "        input_str = json.dumps({\"inputs\": prompt, **model_kwargs})\n",
    "        \n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        \n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        ndim = np.array(response_json).ndim    \n",
    "        \n",
    "        if ndim == 4:\n",
    "            # Original shape (1, 1, n, 768)\n",
    "            emb = response_json[0][0][0]\n",
    "            emb = np.expand_dims(emb, axis=0).tolist()\n",
    "        elif ndim == 2:\n",
    "            # Original shape (n, 1)\n",
    "            emb = []\n",
    "            for ele in response_json:\n",
    "                e = ele[0][0]\n",
    "                emb.append(e)\n",
    "        else:\n",
    "            print(f\"Other # of dimension: {ndim}\")\n",
    "            emb = None\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29fd00e-0980-4e53-b12f-f19c48957bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LLMEmbHandler = KoSimCSERobertaContentHandler()\n",
    "\n",
    "# endpoint_name_emb = \"KoSimCSE-roberta-2023-08-23-14-07-12\"\n",
    "endpoint_name_emb = embedding_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e3ad6-3f8f-4f5e-99b9-c699f735ee74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_emb = SagemakerEndpointEmbeddingsJumpStart(\n",
    "    endpoint_name=endpoint_name_emb,\n",
    "    region_name=aws_region,\n",
    "    content_handler=LLMEmbHandler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a712b-c5d9-4745-b7cb-b625b026e3ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Now, we can build an QA application. <span style=\"color:red\">LangChain makes it extremly simple with following few lines of code</span>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e70c7-1ac4-45ed-8b0b-2e5357e43759",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3b24e61-722c-4a0b-aa8d-15c80ede6f39",
   "metadata": {},
   "source": [
    "# 2 Create OpenSearch domain\n",
    "* Follow below\n",
    "    - https://docs.aws.amazon.com/ko_kr/opensearch-service/latest/developerguide/gsgcreate-domain.html\n",
    "* Add policy (using SDK)\n",
    "    - AmazonOpenSearchServiceFullAccess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c03c91e-f823-4a2a-a172-793ae2fbfae3",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b273f1c7-7d85-4846-b5c7-5873ada46974",
   "metadata": {
    "tags": []
   },
   "source": [
    "**step 1. opensearch console로 이동 후 Navigator에서 Domain 이동 후 Create domain 선택** <BR>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../images/open1.png\" alt=\"Step 1\">\n",
    "</div>\n",
    "    \n",
    "**step 2. domain config 셋팅** <BR>\n",
    "    \n",
    "* Domain name : \n",
    "* Domain creation Method: 사용자 지정생성 (손쉬운생성 선택시 '최대 절수' 오류 발생하는 경우)\n",
    "<div align=\"center\">\n",
    "    <img src=\"../images/open2.png\" alt=\"Step 2\">\n",
    "</div>\n",
    "    \n",
    "\n",
    "* Engine options: OpenSearch_2.7\n",
    "* Network: Public access\n",
    "<div align=\"center\">\n",
    "    <img src=\"../images/open3.png\" alt=\"Step 4\">\n",
    "</div>\n",
    "* Master user: Create master user\n",
    "* Master username, Master password and Confirm master password 입력\n",
    "<div align=\"center\">\n",
    "    <img src=\"../images/open4.png\" alt=\"Step 4\">\n",
    "</div>\n",
    "* 고급클러스터 > 최대절수 선택(손쉬운생성 오류경우)\n",
    "<div align=\"center\">\n",
    "    <img src=\"../images/open5.png\" alt=\"Step 5\">\n",
    "</div>    \n",
    "* 오른쪽 아래 주황색 create 선택\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1194d-fb87-41d3-ad1a-2d8e44c22dee",
   "metadata": {
    "tags": []
   },
   "source": [
    "**step 3. access설정** <BR>\n",
    "\n",
    "* 도메인  보안구성 > 편집 클릭\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../images/open6.png\" alt=\"Step 6\">\n",
    "</div>  \n",
    "\n",
    "* 도메인 수준 엑세스 정책 구성 > Effect : Allow 로 수정 \n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../images/open7.png\" alt=\"Step 7\">\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a6199a-083b-4342-bb42-aefe070803d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "**step 4.Domain enapoint 복사** <BR>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"../images/open8.png\" alt=\"Step 8\">\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1600a7-deb8-45e4-879c-0c5b30b12514",
   "metadata": {},
   "source": [
    "* create_domain: https://boto3.amazonaws.com/v1/documentation/api/1.18.51/reference/services/opensearch.html#OpenSearchService.Client.create_domain\n",
    "*     \n",
    "**It takes about 20 mins**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6025ed87-f583-4664-8b34-4ed80e562922",
   "metadata": {},
   "source": [
    "### boto3를 활용한 Opensearch 생성\n",
    "\n",
    "- 만일 boto3를 사용해서 Opensearch domain을 생성하고 싶다면, `option-opensearch-boto3-create-example.ipynb` 노트북의 파일을 참고해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf6f95-c7f6-4b76-aea7-efebfba3e9f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = \"https://search-rag-opensearch-03-gzwhdpf6dndg2rj2vm3fqvnaxa.us-west-2.es.amazonaws.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d5703-f5ad-4bc8-b16b-8bdb4e6baf2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "http_auth = (\"raguser\", \"QWEqwe123!@#\") # Master username, Master password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9672ec-62eb-41fb-a8cd-eba631429798",
   "metadata": {},
   "source": [
    "### 2.2. load context files and build indexer\n",
    "We are now ready to create scripts which will read data from the local directory, use langchain to create embeddings and then upload the embeddings into OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641287da-35e6-4681-99d4-b26c5bff47dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940201e0-5bab-499e-9028-c71322dff481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = CSVLoader(\n",
    "    file_path=\"../dataset/fsi_smart_faq_ko.csv\",\n",
    "    source_column=\"Source\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "context_documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad0b20-997c-4b70-a4d8-dc94dbbfcb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(context_documents), context_documents[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724a575-c665-494c-bd31-673209d4b58d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2.3. OpenSearch에 Data 입력\n",
    "\n",
    "이 스크립트는 모든 것을 하나로 모으고 문서를 청크로 나눈 다음 langchain 패키지를 사용하여 임베딩을 생성한 다음(`SagemakerEndpointEmbeddingsJumpStart`를 통해) `OpenSearchVectorSearch`를 사용하여 OpenSearch에 데이터를 수집합니다.\n",
    "\n",
    "단순하게 유지하기 위해 청크 크기는 800개 토큰의 고정 길이로 설정되고 200개 토큰이 중복됩니다. langchain `OpenSearchVectorSearch`는 `opensearch-py` 패키지에 대한 래퍼를 제공합니다. 단일 PUT 요청에서 여러 레코드를 수집하기 위해 `/_bulk` API 엔드포인트를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab7d1c6-7b4a-42ef-9c09-581bb63aef07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pprint\n",
    "import logging\n",
    "import sagemaker\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611333f-a1d9-43a0-ba5f-08fbf5b1b520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f7a09a-0bae-4097-aa63-e845a4a2057d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# global constants\n",
    "logger = logging.getLogger()\n",
    "logging.basicConfig(format='%(asctime)s,%(module)s,%(processName)s,%(levelname)s,%(message)s', level=logging.INFO, stream=sys.stderr)\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9813c9-a990-4684-a9fc-9698b809ff3e",
   "metadata": {},
   "source": [
    "### OpenSearch에 Index 생성 및 Vector Store 데이터 저장 전송"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66b1a9-2b6c-45e1-bfbc-4cfaee39813f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = \"fsi-sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162f4988-2579-4d49-8eca-e27f05ffeff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "logger.info('Loading documents ...')\n",
    "docs = loader.load()\n",
    "\n",
    "# # add a custom metadata field, such as timestamp\n",
    "for doc in docs:\n",
    "    doc.metadata['timestamp'] = time.time()\n",
    "    doc.metadata['embeddings_model'] = endpoint_name_emb\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "# by default langchain would create a k-NN index and the embeddings would be ingested as a k-NN vector type\n",
    "docsearch = OpenSearchVectorSearch.from_documents(\n",
    "    index_name=index_name,\n",
    "    documents=documents,\n",
    "    embedding=llm_emb,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    http_auth=http_auth,\n",
    "    bulk_size=10000,\n",
    "    timeout=60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f87c18-22c9-4ad7-88be-2f97c85fc181",
   "metadata": {},
   "source": [
    "## 5. QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d08bd9-231c-4b1f-b8e9-6fdd1cdbfa44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b853fb-1da5-40d2-8540-71fe00e4bf2c",
   "metadata": {},
   "source": [
    "### 5.1. Query and Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac54bb4-2704-40c5-a809-2d34746d6d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import functools\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935448b-3f3c-49a7-8142-8845f6285acd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = ''.join([\"{context}\", seperator, \"{question}\"])\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain = load_qa_chain(llm=llm_text, chain_type=\"stuff\", prompt=PROMPT, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7efae-5339-46d5-bbb2-5402daceb1cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vector DB에 쿼리할 객체를 설정합니다.\n",
    "vectro_db = OpenSearchVectorSearch(\n",
    "    index_name=index_name,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    embedding_function=llm_emb,\n",
    "    http_auth=http_auth, # http_auth\n",
    "    is_aoss =False,\n",
    "    engine=\"faiss\",\n",
    "    space_type=\"l2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68445522-5e7a-4a28-9a95-c2991f8156d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretty_print_documents(response):\n",
    "    for doc, score in response:\n",
    "        print(f'\\nScore: {score}')\n",
    "        print(f'Document Number: {doc.metadata[\"row\"]}')\n",
    "        print(f'Source: {doc.metadata[\"source\"]}')\n",
    "\n",
    "        # Split the page content into lines\n",
    "        lines = doc.page_content.split(\"\\n\")\n",
    "\n",
    "        # Extract and print each piece of information if it exists\n",
    "        for line in lines:\n",
    "            split_line = line.split(\": \")\n",
    "            if len(split_line) > 1:\n",
    "                print(f'{split_line[0]}: {split_line[1]}')\n",
    "\n",
    "        print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf59e1-efb2-4fca-a3dc-47322d31387a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_and_remove_score_opensearch_vector_score(res, cutoff_score = 0.006, variance=0.95):\n",
    "    # Get the lowest score\n",
    "    highest_score = max(score for doc, score in res)\n",
    "    print('highest_score : ', highest_score)\n",
    "    # If the lowest score is over 200, return an empty list\n",
    "    if highest_score < cutoff_score:\n",
    "        return []\n",
    "    # Calculate the upper bound for scores\n",
    "    lower_bound = highest_score * variance\n",
    "    print('lower_bound : ', lower_bound)\n",
    "    # Filter the list and remove the score\n",
    "    res = [doc for doc, score in res if score >= lower_bound]\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_similiar_docs(query, k=5, fetch_k=300, score=True, bank=\"\"):\n",
    "\n",
    "    \n",
    "    #query = f'{bank}, {query}'\n",
    "    print (query)\n",
    "    \n",
    "    if score:\n",
    "        pre_similar_doc = vectro_db.similarity_search_with_score(\n",
    "            query,\n",
    "            k=k,\n",
    "            fetch_k=fetch_k,\n",
    "            search_type=\"approximate_search\", # approximate_search, script_scoring, painless_scripting\n",
    "            space_type=\"l2\",     #\"l2\", \"l1\", \"linf\", \"cosinesimil\", \"innerproduct\", \"hammingbit\";\n",
    "            pre_filter={\"bool\": {\"filter\": {\"term\": {\"text\": bank}}}},\n",
    "            boolean_filter={\"bool\": {\"filter\": {\"term\": {\"text\": bank}}}}\n",
    "            #filter=dict(source=bank)\n",
    "        )\n",
    "        #print('jhs : ', similar_docs)\n",
    "        pretty_print_documents( pre_similar_doc)\n",
    "        similar_docs=filter_and_remove_score_opensearch_vector_score(pre_similar_doc)        \n",
    "    else:\n",
    "        similar_docs = vectro_db.similarity_search(\n",
    "            query,\n",
    "            k=k,\n",
    "            search_type=\"approximate_search\", # approximate_search, script_scoring, painless_scripting\n",
    "            space_type=\"12\",     #\"l2\", \"l1\", \"linf\", \"cosinesimil\", \"innerproduct\", \"hammingbit\";\n",
    "            pre_filter={\"bool\": {\"filter\": {\"term\": {\"text\": bank}}}},\n",
    "            boolean_filter={\"bool\": {\"filter\": {\"term\": {\"text\": bank}}}}\n",
    "            \n",
    "        )\n",
    "    similar_docs_copy = copy.deepcopy(similar_docs)\n",
    "    \n",
    "    #print('similar_docs_copy : \\n', similar_docs_copy)\n",
    "    \n",
    "    return similar_docs_copy\n",
    "\n",
    "\n",
    "def get_answer(query, bank=\"\",score=False, fetch_k=300, k=1):\n",
    "                \n",
    "    search_query = query\n",
    "    \n",
    "    similar_docs = get_similiar_docs(search_query, k=k,score=score, bank=bank)\n",
    "    \n",
    "\n",
    "    llm_query = '고객 서비스 센터 직원처럼, '+query+' 카테고리에 대한 Information을 찾아서 설명해주세요.'\n",
    "    \n",
    "    if not similar_docs:\n",
    "        llm_query = query\n",
    "\n",
    "    answer = chain.run(input_documents=similar_docs, question=llm_query)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c193c6a-822f-4861-badd-697915f0be12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question ='안녕하세요. 날씨가 참 좋네요.'\n",
    "response = get_answer(question, bank='신한은행',score=True, k=4)\n",
    "print(\"챗봇 : \", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92313609-5682-45ca-8eeb-8cf87bfb4270",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q ='간편조회서비스는 회원가입해야하나요?'\n",
    "response = get_answer(q, bank='신한은행',score=True, k=5)\n",
    "\n",
    "print(\"챗봇 : \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce04ab1-4d10-44be-90d4-dfc823c2637c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6226cc-cd67-4bf6-937e-a4b34e0ac3dc",
   "metadata": {},
   "source": [
    "### 6.1. delete opensearch domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244bb1c5-9bb0-4d9a-a9ab-eb111d6d13cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# client = boto3.client('opensearch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f0667-fe91-4cac-8a52-4d8166b8520d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = client.delete_domain(\n",
    "#     DomainName=opnsearch_config[\"domain\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f3239-2593-4ad6-a97f-82732e03d41c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
