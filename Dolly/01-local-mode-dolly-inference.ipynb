{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f4881f9-1f8a-4836-8c3c-ba736ed87308",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dolly local inference 테스트\n",
    "\n",
    "### Dolly 모델 주소\n",
    "- dolly-v2-7b : https://huggingface.co/databricks/dolly-v2-7b\n",
    "- dolly-v2-12b : https://huggingface.co/databricks/dolly-v2-12b\n",
    "\n",
    "### Local mode inference\n",
    "- 일반적인 Jupyter notebook을 사용하는 것과 동일하게 사용할 수 있습니다.\n",
    "\n",
    "### Tested version\n",
    "\n",
    "Tested on `Python 3.9.15`\n",
    "\n",
    "```\n",
    "sagemaker: 2.146.0\n",
    "transformers: 4.29.2\n",
    "torch: 1.13.1\n",
    "accelerate: 0.19.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292ba3f-d3e0-4504-a376-95751d8c8f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ab8358-768f-4c08-9569-4f45f373d09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import transformers\n",
    "import torch\n",
    "import accelerate\n",
    "print(sagemaker.__version__)\n",
    "print(transformers.__version__)\n",
    "print(torch.__version__)\n",
    "print(accelerate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678c2167-5ded-43e7-b925-fd28c006d6e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b120b-c4e4-4ae1-bbae-ccfb6496e4e9",
   "metadata": {},
   "source": [
    "### 모델 다운로드\n",
    "\n",
    "- 로컬에서 테스트를 하기 위해 모델을 다운로드 받습니다. git lfs 명령어를 사용해도 되지만 여기서는 huggingface 에서 제공하는 라이브러리를 사용하였습니다.\n",
    "- git lfs 사용 시 아래와 같이 받을 수 있습니다.\n",
    "```\n",
    "git lfs install\n",
    "git clone https://huggingface.co/databricks/dolly-v2-7b\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a8321-d442-4d21-8880-f2df90f21018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "local_model_path = Path(\"./pretrained-models\")\n",
    "local_model_path.mkdir(exist_ok=True)\n",
    "model_name = \"databricks/dolly-v2-7b\"\n",
    "allow_patterns = [\"*.json\", \"*.pt\", \"*.bin\", \"*.txt\", \"*.model\"]\n",
    "\n",
    "model_download_path = snapshot_download(\n",
    "    repo_id=model_name,\n",
    "    cache_dir=local_model_path,\n",
    "    allow_patterns=allow_patterns,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3b7ed7-6461-4c39-8b94-5c22ebca1a37",
   "metadata": {},
   "source": [
    "### 나중에 사용하기 위해 모델 업로드\n",
    "\n",
    "- 나중에 활용하기 위해 s3에 모델을 업로드 해놓도록 합니다.\n",
    "- huggingface 라이브러리를 사용한 경우에는 상관 없지만, git lfs 를 사용해 다운로드 받은 경우에는 `.git` 디렉토리를 삭제하여 쓸모없는 업로드를 하지 않도록 해야 합니다.\n",
    "\n",
    "### instruct_pipeline.py 다운로드\n",
    "- 실제 생성을 할 때의 pipeline 스크립트는 [여기](https://huggingface.co/databricks/dolly-v2-7b/blob/main/instruct_pipeline.py) 있습니다. 해당 스크립트는 모델 로딩 시 `trust_remote_code=True` 로 설정하면 필요 없지만, 이걸 내장하거나 추후 수정해서 사용할 수 있으므로 현재 디렉토리에 다운받아 놓도록 합니다. 예를 들어 아래와 같이 다운로드 받을 수 있습니다.\n",
    "```\n",
    "wget https://huggingface.co/databricks/dolly-v2-7b/raw/main/instruct_pipeline.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace845a-e92f-4495-b603-e9b86345968d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Model downloaded: {model_download_path}\")\n",
    "s3_model_prefix = \"llm/databricks/dolly-v2-7b/model\"  # folder where model checkpoint will go\n",
    "model_artifact = sagemaker_session.upload_data(path=model_download_path, key_prefix=s3_model_prefix)\n",
    "print(f\"s3 Model uploaded: {model_artifact}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61069db3-69d1-46f2-86ca-818ccfea8ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from instruct_pipeline import InstructionTextGenerationPipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_location = model_download_path\n",
    "\n",
    "# 특정한 위치에 모델 파일들을 넣어놓는 경우\n",
    "# model_location = \"./dolly-imdb-finetune\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_location, padding_side=\"left\")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_location, device_map=\"auto\", torch_dtype=torch.bfloat16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0957e8-f43f-4c97-9bd8-8bb9fdbc1dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_text = InstructionTextGenerationPipeline(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    do_sample = True,\n",
    "    max_new_tokens = 256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efdb511-d3fc-4b1b-a2a2-a8b7f4aa578b",
   "metadata": {},
   "source": [
    "### Inference 테스트\n",
    "\n",
    "- 모델이 성공적으로 로딩되면 테스트를 진행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8df03f-11a4-4b71-b3dc-0d9756bd3f47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Explain to me how to use aws serverless services\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45785715-a16f-44fc-8b62-e160306e2718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f72ea-bc0c-4f58-852c-587a00e2caa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "res = generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c196ee-74b6-4027-84aa-12a20394ba67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(res[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16aedab-724f-42ae-80de-304422041a2d",
   "metadata": {},
   "source": [
    "### 결과\n",
    "- 텍스트가 잘 생성되는 것을 확인할 수 있습니다. Prompt tuning을 통해 더 좋은 결과를 얻을 수 있습니다.\n",
    "- 모델이 업로드된 s3 주소는 추후 사용을 위해서 메모해 놓도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ddbeeb-5ce2-45e7-bf02-b7570b722839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store model_artifact\n",
    "%store model_download_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125104d-9aae-4ab4-93bd-a69e1acada8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
