{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a95910a-4907-4d1d-a4b1-14ef9ba410ed",
   "metadata": {},
   "source": [
    "## StackDolly\n",
    "\n",
    "아래의 StackLLaMA 블로그에서 나온 전체 과정을 SageMaker에서 학습하는 예시입니다. 라이센스 문제로 LLaMA가 아닌 dolly를 활용하여서 진행하도록 합니다.\n",
    "- StackLLaMA : https://huggingface.co/blog/stackllama\n",
    "  - PEFT 활용하여 SFT : https://github.com/lvwerra/trl/blob/main/examples/stack_llama/scripts/supervised_finetuning.py\n",
    "  - reward model 학습 : https://github.com/lvwerra/trl/blob/main/examples/stack_llama/scripts/reward_modeling.py\n",
    "  - reward model 활용하여 RLHF 까지 모두 진행하는 예시 : https://github.com/lvwerra/trl/blob/main/examples/stack_llama/scripts/rl_training.py\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3520ac-dc2d-404f-ba6c-3833c0094e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840e954-5ce5-4955-a745-b577d2f8cf25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.huggingface import HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29982d22-2683-463a-a444-7ec1dae2f144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sm_client = sagemaker_session.sagemaker_client\n",
    "sm_runtime_client = sagemaker_session.sagemaker_runtime_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e76865-4a7c-490b-bc0e-a639781d3c93",
   "metadata": {},
   "source": [
    "### 학습 진행\n",
    "\n",
    "DeepSpeed + Accelerate 를 활용한 분산 학습 예시\n",
    "- SageMaker를 활용해서 mutli-node & multi-gpu로 DeepSpeed + Accelerate하는 예시는 여기를 참고해 주세요: https://github.com/aws-samples/training-llm-on-sagemaker-for-multiple-nodes-with-deepspeed \n",
    "- SageMaker 자체도 EC2 instance를 할당 받은 후 학습을 하는 것이기 때문에, 위에서 나온 것 처럼 entrypoint에서는 학습을 위한 스크립트를 별도로 실행하도록 하였고, 이 방법을 활용하면 높은 자유도를 가지고 웬만한 형태의 distributed training이 모두 가능함.\n",
    "\n",
    "### 코드 작성\n",
    "\n",
    "- 실제 학습 코드에 관해서는 `stack-dolly-src` 디렉토리를 참고 해 주세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0b5b7d-0fc2-4a7a-bb95-71b938be9bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_name = name_from_base(\"stack-dolly\")\n",
    "print(job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a0ab7-9c3f-4880-9a38-afc63a76c7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instance_type = 'ml.p3.16xlarge'\n",
    "instance_type = 'ml.g5.12xlarge'\n",
    "# instance_type = 'ml.g5.24xlarge'\n",
    "# instance_type = 'ml.g5.48xlarge'\n",
    "# instance_type = 'ml.p4d.24xlarge'\n",
    "\n",
    "instance_count = 1\n",
    "environment = {'NODE_NUMBER': str(instance_count)}\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'start.py',          # user endpoint script\n",
    "    source_dir           = 'stack-dolly-src',               # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type, # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    transformers_version = '4.26',            # the transformers version used in the training job\n",
    "    pytorch_version      = '1.13',            # the pytorch_version version used in the training job\n",
    "    py_version           = 'py39',            # the python version used in the training job\n",
    "    environment = environment,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118ce5f2-39b1-4f72-bc8a-144cda2aa02c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_uri = model_artifact\n",
    "data = {'pretrained-model': pretrained_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c487e-6dfb-47fa-a0f8-41a5bb8b0e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.fit(data, wait=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352d33a-56c4-4adc-8bd0-07d76b8f5776",
   "metadata": {},
   "source": [
    "### Next step (Homework)\n",
    "\n",
    "- SFT 학습이 완료되면, reward modeling 및 RLHF 학습 모두 순차적으로 진행하면 됩니다.\n",
    "- 기존 `stack-dolly-src` 에 있는 코드를 참고하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c93015-3668-496d-b2f6-2303e8082736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392ded55-d99b-4f3d-b121-0b5da69043ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
